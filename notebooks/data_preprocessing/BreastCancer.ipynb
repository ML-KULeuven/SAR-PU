{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sarpu.data_processing import *\n",
    "from sarpu.paths_and_names import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names and locations\n",
    "data_folder = \"../../Data/\"\n",
    "data_name = \"breastcancer\"\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation information\n",
    "nb_splits = 5\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare folders\n",
    "data_folder_original = original_data_path(data_folder,data_name)\n",
    "!mkdir -p $data_folder_original\n",
    "data_folder_processed = processed_data_path(data_folder,data_name)\n",
    "!mkdir -p $data_folder_processed\n",
    "data_folder_partitions = partitions_data_path(data_folder,data_name)\n",
    "!mkdir -p $data_folder_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data_path = os.path.join(data_folder_original,url.split(\"/\")[-1])\n",
    "if not(os.path.exists(unprocessed_data_path)):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(unprocessed_data_path, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data to pandas dataframe\n",
    "\n",
    "#    #  Attribute                     Domain\n",
    "#    -- -----------------------------------------\n",
    "#    1. Sample code number            id number\n",
    "#    2. Clump Thickness               1 - 10\n",
    "#    3. Uniformity of Cell Size       1 - 10\n",
    "#    4. Uniformity of Cell Shape      1 - 10\n",
    "#    5. Marginal Adhesion             1 - 10\n",
    "#    6. Single Epithelial Cell Size   1 - 10\n",
    "#    7. Bare Nuclei                   1 - 10\n",
    "#    8. Bland Chromatin               1 - 10\n",
    "#    9. Normal Nucleoli               1 - 10\n",
    "#   10. Mitoses                       1 - 10\n",
    "#   11. Class:                        (2 for benign, 4 for malignant)\n",
    "\n",
    "\n",
    "\n",
    "header = [\n",
    "    \"Sample code number\",\n",
    "    \"Clump Thickness\",\n",
    "    \"Uniformity of Cell Size\",\n",
    "    \"Uniformity of Cell Shape\",\n",
    "    \"Marginal Adhesion\",\n",
    "    \"Single Epithelial Cell Size\",\n",
    "    \"Bare Nuclei\",\n",
    "    \"Bland Chromatin\",\n",
    "    \"Normal Nucleoli\",\n",
    "    \"Mitoses\",\n",
    "    \"class\",\n",
    "]\n",
    "\n",
    "multival = []\n",
    "\n",
    "\n",
    "df = pd.read_csv(unprocessed_data_path, names=header).replace('?', np.NaN).dropna()\n",
    "df = df.drop(header[0],axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class distribution\n",
    "\n",
    "df[\"class\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make malignant (4) positive class\n",
    "\n",
    "df.loc[df[\"class\"]==2,\"class\"]=0\n",
    "df.loc[df[\"class\"]==4,\"class\"]=1\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarize multivalued features\n",
    "\n",
    "for column in multival:\n",
    "    values = list(set(df[column]))\n",
    "    if len(values)>2:\n",
    "        df = binarize(df, column)\n",
    "    elif len(values)==2:\n",
    "        df.loc[df[column]==values[0],column]=-1\n",
    "        df.loc[df[column]==values[1],column]=1\n",
    "    else: # drop useless features\n",
    "        print(column, values)\n",
    "        df=df.drop(column, axis=1)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "for column in df.columns.values:\n",
    "    df[column]=pd.to_numeric(df[column])\n",
    "\n",
    "normalized_df=(df.astype(float)-df.min())/(df.max()-df.min())*2-1\n",
    "normalized_df[\"class\"] = df[\"class\"]\n",
    "df = normalized_df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#move class to back\n",
    "\n",
    "cols = list(df.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('class')) #Remove class from list\n",
    "df = df[cols+['class']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make numpy array\n",
    "xy = df.values\n",
    "\n",
    "x = xy[:,:-1].astype(float)\n",
    "y = xy[:,-1].astype(int)\n",
    "\n",
    "x_pos = x[y==1]\n",
    "x_neg = x[y==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data and true classes\n",
    "np.savetxt(data_path(data_folder, data_name), x)\n",
    "np.savetxt(classlabels_path(data_folder, data_name), y,fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different dataset partitions (train/test and class prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = sklearn.model_selection.StratifiedShuffleSplit(n_splits=nb_splits, test_size=test_size, random_state=0)\n",
    "splits = list(sss.split(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save partitions. 0 means not in data, 1 means in train partition, 2 means in test partition\n",
    "\n",
    "for i, (train,test) in enumerate(splits):\n",
    "    partition = np.zeros_like(y,dtype=int)\n",
    "    partition[train]=1\n",
    "    \n",
    "    partition[test]=2    \n",
    "    np.savetxt(partition_path(data_folder,data_name, i), partition, fmt='%d')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sarpupub",
   "language": "python",
   "name": "env_sarpupub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
